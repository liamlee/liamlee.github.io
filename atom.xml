<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Liamming</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liamlee.github.io/"/>
  <updated>2017-01-16T10:55:24.000Z</updated>
  <id>https://liamlee.github.io/</id>
  
  <author>
    <name>Ming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>斯坦福(吴恩达)-机器学习-第二周编程作业代码笔记</title>
    <link href="https://liamlee.github.io/2017/01/16/linearRegression/"/>
    <id>https://liamlee.github.io/2017/01/16/linearRegression/</id>
    <published>2017-01-16T10:38:27.000Z</published>
    <updated>2017-01-16T10:55:24.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h4><p>以下编程逻辑基于此处定义的假设函数<br>$$<br>h_\theta(x) = \theta^T\vec x<br>$$</p>
<p>$$<br>h_\theta(x) = \theta_0 + \theta_1x<br>$$</p>
<h4 id="computeCost"><a href="#computeCost" class="headerlink" title="computeCost"></a>computeCost</h4><p>回归问题中，通常选用Square error function<br>$$<br>J(\theta) = \frac{1} {2m}\sum<em>{i=1}^m(h</em>\theta(x^{(i)}) - y^{(i)})^2<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">function J = computeCost(X, y, theta)</div><div class="line">%COMPUTECOST Compute cost for linear regression</div><div class="line">%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the</div><div class="line">%   parameter for linear regression to fit the data points in X and y</div><div class="line"></div><div class="line">% Initialize some useful values</div><div class="line">m = length(y); % number of training examples</div><div class="line"></div><div class="line">% You need to return the following variables correctly </div><div class="line">J = 0;</div><div class="line"></div><div class="line">% ====================== YOUR CODE HERE ======================</div><div class="line">% Instructions: Compute the cost of a particular choice of theta</div><div class="line">%               You should set J to the cost.</div><div class="line">h = theta&apos; .* X ;</div><div class="line">J = sum((h(:,1) + h(:,2) - y) .^ 2) / m / 2 ;</div><div class="line"></div><div class="line">% =========================================================================</div><div class="line"></div><div class="line">end</div></pre></td></tr></table></figure>
<h4 id="computeCost-多维"><a href="#computeCost-多维" class="headerlink" title="computeCost-多维"></a>computeCost-多维</h4><p>多维情况下，为了更直观的指导编程，我们可以对函数表达式做一下改写<br>$$<br>J(\theta) = \frac{1}{2m}(X\theta - \vec y)^T(X\theta - \vec y)<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">function J = computeCostMulti(X, y, theta)</div><div class="line">%COMPUTECOSTMULTI Compute cost for linear regression with multiple variables</div><div class="line">%   J = COMPUTECOSTMULTI(X, y, theta) computes the cost of using theta as the</div><div class="line">%   parameter for linear regression to fit the data points in X and y</div><div class="line"></div><div class="line">% Initialize some useful values</div><div class="line">m = length(y); % number of training examples</div><div class="line"></div><div class="line">% You need to return the following variables correctly </div><div class="line">J = 0;</div><div class="line"></div><div class="line">% ====================== YOUR CODE HERE ======================</div><div class="line">% Instructions: Compute the cost of a particular choice of theta</div><div class="line">%               You should set J to the cost.</div><div class="line">% J = 1/(2*m) * (theta * X&apos; - y)&apos;(theta * X&apos; - y)</div><div class="line">h = theta&apos; .* X ;</div><div class="line">s = size(h,2);</div><div class="line">j = h(:,1);</div><div class="line"></div><div class="line">for i = 2:s</div><div class="line">  j = j + h(:,i);</div><div class="line">end</div><div class="line"></div><div class="line">j = j - y;</div><div class="line"></div><div class="line">J = sum(sum(j&apos; * j)) / m / 2;</div><div class="line">% =========================================================================</div><div class="line">end</div></pre></td></tr></table></figure>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>批量梯度下降迭代过程中，每次迭代同时更新所有<em>theta</em>，并且使用所有训练样本<br>$$<br>\theta_j := \theta<em>j - \alpha\frac1m\sum</em>{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)</div><div class="line">%GRADIENTDESCENT Performs gradient descent to learn theta</div><div class="line">%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </div><div class="line">%   taking num_iters gradient steps with learning rate alpha</div><div class="line"></div><div class="line">% Initialize some useful values</div><div class="line">m = length(y); % number of training examples</div><div class="line">J_history = zeros(num_iters, 1);</div><div class="line"></div><div class="line">for iter = 1:num_iters</div><div class="line">    % ====================== YOUR CODE HERE ======================</div><div class="line">    % Instructions: Perform a single gradient step on the parameter vector</div><div class="line">    %               theta. </div><div class="line">    %</div><div class="line">    % Hint: While debugging, it can be useful to print out the values</div><div class="line">    %       of the cost function (computeCost) and gradient here.</div><div class="line">    %</div><div class="line">    h = theta&apos; .* X ;</div><div class="line"></div><div class="line">    theta(1) = theta(1) - sum((h(:,1) + h(:,2) - y)&apos; * X(:,1)) * alpha / m;</div><div class="line">    theta(2) = theta(2) - sum((h(:,1) + h(:,2) - y)&apos; * X(:,2)) * alpha / m;</div><div class="line"></div><div class="line">    % ============================================================</div><div class="line"></div><div class="line">    % Save the cost J in every iteration    </div><div class="line">    J_history(iter) = computeCost(X, y, theta);</div><div class="line">end</div></pre></td></tr></table></figure>
<h4 id="梯度下降-多维"><a href="#梯度下降-多维" class="headerlink" title="梯度下降-多维"></a>梯度下降-多维</h4><p>多维与前面特殊情况一样，需要注意的在编写程序时确保能支持任意维度的求解，而不是前面固定只求<em>theta1</em>、<em>theta2</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)</div><div class="line">%GRADIENTDESCENTMULTI Performs gradient descent to learn theta</div><div class="line">%   theta = GRADIENTDESCENTMULTI(x, y, theta, alpha, num_iters) updates theta by</div><div class="line">%   taking num_iters gradient steps with learning rate alpha</div><div class="line"></div><div class="line">% Initialize some useful values</div><div class="line">m = length(y); % number of training examples</div><div class="line">J_history = zeros(num_iters, 1);</div><div class="line">for iter = 1:num_iters</div><div class="line"></div><div class="line">    % ====================== YOUR CODE HERE ======================</div><div class="line">    % Instructions: Perform a single gradient step on the parameter vector</div><div class="line">    %               theta. </div><div class="line">    %</div><div class="line">    % Hint: While debugging, it can be useful to print out the values</div><div class="line">    %       of the cost function (computeCostMulti) and gradient here.</div><div class="line">    %</div><div class="line">    h = theta&apos; .* X ;</div><div class="line">    s = size(h,2);</div><div class="line"></div><div class="line">    j = h(:,1);</div><div class="line">    for i = 2:s</div><div class="line">      j = j + h(:,i);</div><div class="line">    end</div><div class="line">    j = j - y;</div><div class="line">    </div><div class="line">    s = size(theta,1);</div><div class="line">    for i = 1:s</div><div class="line">      theta(i) = theta(i) - sum(j&apos; * X(:,i)) * alpha / m;</div><div class="line">    end</div><div class="line">    % ============================================================</div><div class="line"></div><div class="line">    % Save the cost J in every iteration    </div><div class="line">    J_history(iter) = computeCostMulti(X, y, theta);</div><div class="line">end</div></pre></td></tr></table></figure>
<h4 id="特征正则化"><a href="#特征正则化" class="headerlink" title="特征正则化"></a>特征正则化</h4><p>采用均值和标准差对特征数据做正则化</p>
<ul>
<li>求得每个维度的均值、标准差</li>
<li>每个维度减去该维度的均值，然后除以标准差</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">function [X_norm, mu, sigma] = featureNormalize(X)</div><div class="line">%FEATURENORMALIZE Normalizes the features in X </div><div class="line">%   FEATURENORMALIZE(X) returns a normalized version of X where</div><div class="line">%   the mean value of each feature is 0 and the standard deviation</div><div class="line">%   is 1. This is often a good preprocessing step to do when</div><div class="line">%   working with learning algorithms.</div><div class="line"></div><div class="line">% You need to set these values correctly</div><div class="line">X_norm = X;</div><div class="line">mu = zeros(1, size(X, 2));</div><div class="line">sigma = zeros(1, size(X, 2));</div><div class="line"></div><div class="line">% ====================== YOUR CODE HERE ======================</div><div class="line">% Instructions: First, for each feature dimension, compute the mean</div><div class="line">%               of the feature and subtract it from the dataset,</div><div class="line">%               storing the mean value in mu. Next, compute the </div><div class="line">%               standard deviation of each feature and divide</div><div class="line">%               each feature by it&apos;s standard deviation, storing</div><div class="line">%               the standard deviation in sigma. </div><div class="line">%</div><div class="line">%               Note that X is a matrix where each column is a </div><div class="line">%               feature and each row is an example. You need </div><div class="line">%               to perform the normalization separately for </div><div class="line">%               each feature. </div><div class="line">%</div><div class="line">% Hint: You might find the &apos;mean&apos; and &apos;std&apos; functions useful.</div><div class="line">%       </div><div class="line">mu = mean(X);</div><div class="line">sigma = std(X);</div><div class="line"></div><div class="line">s = size(X,2);</div><div class="line">for iter = 1:s</div><div class="line">  X_norm(:,iter) = (X_norm(:,iter) - mu(iter)) ./ sigma(iter);</div><div class="line">end</div><div class="line">% ============================================================</div><div class="line">end</div></pre></td></tr></table></figure>
<h4 id="Normal-Equation-正规方程"><a href="#Normal-Equation-正规方程" class="headerlink" title="Normal Equation(正规方程)"></a>Normal Equation(正规方程)</h4><p>根据假设函数，我们可以通过方程转换的到Normal Equation表达式直接计算得到<em>theta</em><br>$$<br>\theta = (X^TX)^{-1}X^ T\vec y<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">function [theta] = normalEqn(X, y)</div><div class="line">%NORMALEQN Computes the closed-form solution to linear regression </div><div class="line">%   NORMALEQN(X,y) computes the closed-form solution to linear </div><div class="line">%   regression using the normal equations.</div><div class="line"></div><div class="line">theta = zeros(size(X, 2), 1);</div><div class="line"></div><div class="line">% ====================== YOUR CODE HERE ======================</div><div class="line">% Instructions: Complete the code to compute the closed form solution</div><div class="line">%               to linear regression and put the result in theta.</div><div class="line">%</div><div class="line"></div><div class="line">% ---------------------- Sample Solution ----------------------</div><div class="line">theta = (X&apos; * X)^(-1) * X&apos; * y;</div><div class="line">% -------------------------------------------------------------</div><div class="line">% ============================================================</div><div class="line">end</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;假设函数&quot;&gt;&lt;a href=&quot;#假设函数&quot; class=&quot;headerlink&quot; title=&quot;假设函数&quot;&gt;&lt;/a&gt;假设函数&lt;/h4&gt;&lt;p&gt;以下编程逻辑基于此处定义的假设函数&lt;br&gt;$$&lt;br&gt;h_\theta(x) = \theta^T\vec x&lt;br&gt;$$&lt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://liamlee.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="https://liamlee.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="LinearRegression" scheme="https://liamlee.github.io/tags/LinearRegression/"/>
    
  </entry>
  
  <entry>
    <title>回首2016</title>
    <link href="https://liamlee.github.io/2016/12/29/look-back-2016/"/>
    <id>https://liamlee.github.io/2016/12/29/look-back-2016/</id>
    <published>2016-12-29T15:30:13.000Z</published>
    <updated>2017-01-01T03:16:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>2016又即将过去，就像每个今天变成昨天，今年的2016就要变成去年2016了。我已经忘记了2016年年初有没有定下一些目标，所以不敢说完成了什么。在这里现在只能做一点回忆，做一点总结，或许写到最后还会做一点规划，定下一些目标。</p>
<h3 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h3><p>收货的话，今年确实收了不少，但是收获从何说起呢？</p>
<p>读书一定可以算得上是一个，这一年虽然没有刻意的按照一个量化的目标去读书，但确实没有停止读书，读书习惯较之前可以说是更好了一些。2016年，实实在在读完的书有那么几本。</p>
<p>《易中天中华史》系列，目前出版的有17本，从我们的祖先时代读到隋唐时代，最新的关于大宋的一本暂时还没读。十六本通读下来，首先佩服易老师致力写这么一套书，书中体现出易老师严谨的历史态度，就算有偏好的历史人物，在阐述“事实”的时候也是基于严谨的史料考据和客观的态度。</p>
<p>中学上了四年的历史课，大学一年，都没有学到一点历史观，所有为了考试背诵的历史年份、历史人物、历史事件，都在考试后忘得一干二净。</p>
<p>在阅读这一套丛书的时候，历史思维、历史观开始一点点建立起来了，对待历史人物、历史事件有了新的看法和思考，这种思考也顺便融入了对现在的思考中。对比历史各个时期，现在的人在很多方面都有了巨大的进步，比如科技，比如文明，但也有些方面感觉上似乎没有多大进步，比如人们依然不知道幸福为何物，面对“哲学三问”依然茫然。</p>
<p>读了几本不错的小说《嫌疑人X的献身》、《钟鼓楼》，刘心武先生的《钟鼓楼》着实让我印象深刻。起先并没有看过刘老师的书，知道他是从百家讲坛，但仅仅是知道，因为他讲的“解密红楼梦”我也没看过。然而这本小说让我惊叹刘老师人物刻画的功力。将北京浓缩在一个四合院中，有血有肉、个性鲜明的小人物身上。故事没有开始更没有结尾，因为人们一代又一代故事怎么讲得完。</p>
<p>另外，基本经济类的书籍，《斯坦福极简经济学》、《一本书通读10位经济学大师》。不敢说读完后就懂了经济学，但是多少有些一些经济学思维。</p>
<h3 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h3><h3 id="迷茫"><a href="#迷茫" class="headerlink" title="迷茫"></a>迷茫</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2016又即将过去，就像每个今天变成昨天，今年的2016就要变成去年2016了。我已经忘记了2016年年初有没有定下一些目标，所以不敢说完成了什么。在这里现在只能做一点回忆，做一点总结，或许写到最后还会做一点规划，定下一些目标。&lt;/p&gt;
&lt;h3 id=&quot;收获&quot;&gt;&lt;a hre
    
    </summary>
    
    
      <category term="总结" scheme="https://liamlee.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Spark-Notebook安装与调教</title>
    <link href="https://liamlee.github.io/2016/12/28/sparkNotebook-install/"/>
    <id>https://liamlee.github.io/2016/12/28/sparkNotebook-install/</id>
    <published>2016-12-28T03:02:46.000Z</published>
    <updated>2016-12-29T11:46:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>近来，忙活了一段时间的项目被宣布暂时停下来，另外一条线的工作也因为等待数据中暂时无法开展起来，忽然间感觉所有工作都戛然而止了。那么，就领着“大数据平台规划”的任务折腾一些新的东西吧。依据“可视化数据分析”的概念摸摸索索，发现了SparkNotebook。下面就是这个工具的安装配置笔记。</p>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><ul>
<li>直接去<a href="http://spark-notebook.io" target="_blank" rel="external">官网</a>下载编译好的包，作者提供了非常非常详尽的下载列表，所有压缩方式、版本支持、组件支持的组合一一列在了主页面，擦亮双眼找出你理想的版本下载即可。</li>
<li>去<a href="https://github.com/andypetrella/spark-notebook/" target="_blank" rel="external">Github主页</a>下载源码，然后自行编译。看到官网那么详细的列表，我猜想要自行编译出个性化的包一定很麻烦，所以我直接选择放弃源码编译。</li>
</ul>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>Spark Notebook的安装可以说非常简单，就是一个步骤：解~压~缩~。环境变量你想配或者不配，随你大小便咯。完成解压后，就可以运行起来了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd spark-notebook-0.7.0</div><div class="line">./bin/spark-notebook</div></pre></td></tr></table></figure>
<p>在浏览器输入<code>http://your-host:9001</code>，即可访问notebook。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p><em>配置永远是重头戏</em></p>
<p>配置文件列表：</p>
<ul>
<li>conf/application.conf</li>
<li>conf/application.ini</li>
<li>conf/clusters</li>
<li>conf/profiles</li>
</ul>
<p>其实尴尬了，细细盘点一下，发现没有对上述配置文件动过什么手脚。所以，只剩下一下遇坑爬坑的心得了，作为一个知识积累放在这里，如顺便能对其他查阅者有所帮助，那最好不过了。</p>
<ul>
<li><p><strong>连接已有的Spark集群来做数据分析</strong></p>
<ol>
<li><p>代码方式：在创建SparkSession时直接指定集群的master。不！奏！效！</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span></div><div class="line">      .builder()</div><div class="line">      .config(<span class="string">"spark.master"</span>,<span class="string">"spark://node1:7077"</span>)</div><div class="line">      .getOrCreate()</div></pre></td></tr></table></figure>
</li>
<li><p>配置“Notebook Metadata”方式：<em>这里演示的是standalone模式</em></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">"customSparkConf": &#123;</div><div class="line">    "spark.app.name": "Notebook",</div><div class="line">    "spark.master": "spark://node1:7077",</div><div class="line">    "spark.executor.memory": "10G",</div><div class="line">    "spark.cores.max": 10,</div><div class="line">    "spark.executor.cores": 2</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</li>
<li><p>配置conf/clusters文件，在clusters文件中，我们可以看到作者已经针对各种集群任务提交模式写了example。我们可以修改其中的“customSparkConf”做个性化修改，配置你的集群信息，具体格式与上一点一样。</p>
</li>
</ol>
</li>
<li><p><strong>连接Hadoop读取HDFS文件</strong></p>
<ol>
<li><p>代码方式：在文件路径前添加HDFS地址前缀“hdfs://servesr/dataPath”</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> testRDD = sc.textFile(<span class="string">"hdfs://node1/data/test.txt"</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>配置$HADOOP_CONF_DIR。很多人对这个可能没有感觉这里有坑。我踩坑是因为环境变量的问题，我的集群没有将HADOOP_CONF_DIR配置到系统(用户)环境变量中，只是在spark-env.sh中export了HADOOP_CONF_DIR，所以Spark集群本身没有问题。</p>
<p>爬坑过程异常烦躁，官方doc就没有提这事，估计觉着这就不是事。网上找吧，基本没有相关博客，github主页中的issue栏目也没有发现谁碰到了这个问题。无奈，翻遍上面提到的几个配置文件，也没发现这个配置项。</p>
<p>最后，只有一个地方了，启动脚本(<code>bin/spark-notebook</code>)。终于找到了线索：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">declare -r app_classpath=&quot;$&#123;CLASSPATH_OVERRIDES&#125;:$&#123;YARN_CONF_DIR&#125;:$&#123;HADOOP_CONF_DIR&#125;:$&#123;EXTRA_CLASSPATH&#125;</div></pre></td></tr></table></figure>
<p>notebook在启动的时候读取了环境变量，那就好办了，在~/.bashrc中添加HADOOP_CONF_DIR变量即可。当然YARN_CONF_DIR也是同样的道理。</p>
<p>另外提一点，这里发现<em>CLASSPATH_OVERRIDES</em>这个变量，我觉得这个变量可以配置spark-notebook自己需要的CLASSPATH，比如<em>figaro</em>(这个也是折腾我好半天)，避免常规的CLASSPATH太重。</p>
</li>
</ol>
</li>
<li><p>Metadata配置，这个暂时不表，后续使用过程中，应该主要在于包依赖配置。</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近来，忙活了一段时间的项目被宣布暂时停下来，另外一条线的工作也因为等待数据中暂时无法开展起来，忽然间感觉所有工作都戛然而止了。那么，就领着“大数据平台规划”的任务折腾一些新的东西吧。依据“可视化数据分析”的概念摸摸索索，发现了SparkNotebook。下面就是这个工具的安
    
    </summary>
    
    
      <category term="大数据" scheme="https://liamlee.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Spark" scheme="https://liamlee.github.io/tags/Spark/"/>
    
      <category term="安装教程" scheme="https://liamlee.github.io/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Hue 安装配置</title>
    <link href="https://liamlee.github.io/2016/12/26/Hue-Install/"/>
    <id>https://liamlee.github.io/2016/12/26/Hue-Install/</id>
    <published>2016-12-26T07:37:29.000Z</published>
    <updated>2016-12-29T11:51:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>Hue</p>
<h3 id="基础依赖"><a href="#基础依赖" class="headerlink" title="基础依赖"></a>基础依赖</h3><ul>
<li>JDK</li>
<li>Maven</li>
<li>Git（用于从github下载Hue） </li>
<li>集群嘛，当然我认为你已经搭建好了</li>
<li>库包依赖：参考Hue的githu主页 <a href="https://github.com/cloudera/hue" target="_blank" rel="external">Hue</a> 所列的所有依赖，一一检查安装</li>
</ul>
<hr>
<h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/cloudera/hue.git (brach)</div><div class="line">cd hue</div><div class="line">make apps</div></pre></td></tr></table></figure>
<p>make过程时间会比较长，只要前面所提的依赖都已安装好，整个过程一般不会出现错误，耐心等待即可</p>
<h3 id="初步验证"><a href="#初步验证" class="headerlink" title="初步验证"></a>初步验证</h3><ul>
<li>在后台启动服务 <code>build/env/bin/hue runserver</code></li>
</ul>
<ul>
<li>访问<a href="http://localhost:8000。正常情况，前台出现登录界面。" target="_blank" rel="external">http://localhost:8000。正常情况，前台出现登录界面。</a></li>
</ul>
<ul>
<li>Hue初始界面没有用户注册选项，直接根据用户的的输入创建第一个超级用户，后续建立用户分配权限都依赖该用户，所以需要特别注意，务必记住自己输入了什么。</li>
</ul>
<hr>
<h3 id="配置Hue"><a href="#配置Hue" class="headerlink" title="配置Hue"></a>配置Hue</h3><p>在完成安装和初步验证后，现在进入最重要也是最复杂的步骤，配置。Hue支持Hadoop生态系统中的各种组建，比如访问HDFS文件、执行SQL查询HBase中的表、编写notebook来运行spark，前提是要做好对应的配置。</p>
<p><strong>配置文件</strong><br>从github下载的开发版，配置文件为 <strong><em>desktop/conf/pseudo-distributed.ini</em></strong> ,如果是其他发行版请参考 <a href="http://gethue.com/how-to-configure-hue-in-your-hadoop-cluster/" target="_blank" rel="external">官方文档</a> 。</p>
<h4 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[beeswax]</div><div class="line">  # Host where HiveServer2 is running. </div><div class="line">  # 如果Hue与Hive不在同一台服务器，需要修改指定正确的Hive服务主机.</div><div class="line">  hive_server_host=localhost</div></pre></td></tr></table></figure>
<p>有些朋友说“我从来不用Hive”，但是Hue执行交互式SQL查询是通过Hive完成的，所以还是建议乖乖的安装配置好Hive在你的集群中吧，至于怎么安装Hive不在此赘述。</p>
<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>首先修改Hadoop配置文件，增加WebHDFS功能，支持通过web访问HDFS</p>
<ul>
<li><p>hdfs-site.xml </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hue.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hue.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>然后对接Hue配置，如果Hue与NameNode在同一台机器，保持默认即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[[hdfs_clusters]]</div><div class="line">    # HA support by using HttpFs</div><div class="line">    [[[default]]]</div><div class="line">      # Enter the filesystem uri</div><div class="line">      fs_defaultfs=hdfs://node1:8020</div><div class="line"></div><div class="line">      # Use WebHdfs/HttpFs as the communication mechanism.</div><div class="line">      # Domain should be the NameNode or HttpFs host.</div><div class="line">      # Default port is 14000 for HttpFs.</div><div class="line">       webhdfs_url=http://node1:50070/webhdfs/v1</div></pre></td></tr></table></figure>
<p>另外一点需特别注意的，为了获取HDFS访问权限，务必指定Hadoop用户</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># This should be the hadoop cluster admin</div><div class="line">   default_hdfs_superuser=your-user</div></pre></td></tr></table></figure>
<h4 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h4><p>监控Job，需要配置ProxyServer 和 Job History servers。<br>首先，Hadoop侧的配置修改</p>
<ul>
<li><p>mapred-site.xml (<em>Job History servers</em>)</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;your-host&#125;:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p>启动Job History server服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mr-jobhistory-daemon.sh start historyserver</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>yarn-site.xml (<em>ProxyServer</em>)</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;your-host&#125;:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;your-host&#125;:8888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p>启动ProxyServer服务    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn-daemon.sh start proxyserver</div></pre></td></tr></table></figure>
</li>
</ul>
<p>对接Hue配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[hadoop]</div><div class="line">  [[yarn_clusters]]</div><div class="line">    [[[default]]]</div><div class="line">      # Enter the host on which you are running the ResourceManager</div><div class="line">      resourcemanager_host=your-host     </div><div class="line">      # Whether to submit jobs to this cluster</div><div class="line">      submit_to=True</div><div class="line">      # URL of the ResourceManager API</div><div class="line">      resourcemanager_api_url=http://your-host:8088</div><div class="line">      # URL of the ProxyServer API</div><div class="line">      proxy_api_url=http://your-host:8088</div><div class="line">      # URL of the HistoryServer API</div><div class="line">      history_server_api_url=http://your-host:19888</div></pre></td></tr></table></figure>
<p>好了，现在你可以Job Browser浏览所有运行的Job并查看日志。</p>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h4><p>HBase配置相对简单，只要指定HBase服务的host即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[hbase]</div><div class="line"># Comma-separated list of HBase Thrift server 1 for clusters in the format of</div><div class="line"> &apos;(name|host:port)&apos;.</div><div class="line">hbase_clusters=(Cluster|your-host:9090)</div></pre></td></tr></table></figure>
<p>然后，务必记得在HMaster所在主机启动Thrift服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hbase thrift start &amp;</div></pre></td></tr></table></figure></p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>更新中……</p>
<hr>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><ol>
<li><a href="http://gethue.com/how-to-configure-hue-in-your-hadoop-cluster/" target="_blank" rel="external">how-to-configure-hue-in-your-hadoop-cluster</a></li>
<li><a href="https://github.com/cloudera/hue" target="_blank" rel="external">Hue-Github</a></li>
<li><a href="http://livy.io/quickstart.html" target="_blank" rel="external">Livy, an Open Source REST Service for Apache Spark</a> </li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hue&lt;/p&gt;
&lt;h3 id=&quot;基础依赖&quot;&gt;&lt;a href=&quot;#基础依赖&quot; class=&quot;headerlink&quot; title=&quot;基础依赖&quot;&gt;&lt;/a&gt;基础依赖&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;JDK&lt;/li&gt;
&lt;li&gt;Maven&lt;/li&gt;
&lt;li&gt;Git（用于从github下载Hu
    
    </summary>
    
    
      <category term="大数据" scheme="https://liamlee.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hue" scheme="https://liamlee.github.io/tags/Hue/"/>
    
  </entry>
  
  <entry>
    <title>读《嫌疑人X的献身》</title>
    <link href="https://liamlee.github.io/2016/11/08/read-xianyirenXdexianshen/"/>
    <id>https://liamlee.github.io/2016/11/08/read-xianyirenXdexianshen/</id>
    <published>2016-11-08T15:04:22.000Z</published>
    <updated>2016-11-14T06:01:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>富㭴慎二：一个看似成功的汽车销售，其实是利用职务之便挥霍公款，出手阔错。追求到花岗靖子，组成了一个看似美满的家庭。东窗事发后，被公司开除，露出了游手好闲的本性，变成一个吃软饭的无赖，离婚后还阴魂不散的缠着花岗靖子。</p>
<p>花岗靖子：一个带着不算小魅力的单身女人，两度婚姻失败，原本在酒廊做陪酒女，为躲避恶棍一般的前夫，带着女儿离开原来的地方，来到朋友小代子的便当店里帮忙。她的到来，石神多了个邻居，石神有了活着的新意义。也因为她的不得已错手杀了前来纠缠的前夫，把石神带入了一条不归路。</p>
<p>石神哲哉：一个数学天才，有着强大的逻辑能力，无奈造化弄人，只能做一个高中数学老师，默默无闻的活着，甚至有过不愿意继续活着的念头。当新来的邻居靖子过来打招呼的时候，石神立即就被深深的吸引住了，似乎有了继续活下去的理由了，以至于在靖子犯下命案的时候，第一时间就出手相助，并在必要的时候献身自己。石神处理了富㭴慎二的尸体，极其隐秘的处理了；石神在第二天制造了另一起命案，杀了一个流浪汉，并直接暴露其尸体；石神制造一系列明显的又模糊的线索，并通过例外的请假制造自己无法证明的不在场证明；石神给靖子想好一系列的对付盘问的话语和方法。最后石神在汤川的识破后献身了自己。</p>
<p>草薙俊平： 一个能力不算差的刑侦警察，陷入了石神为靖子制造的完美的不在场证明里面，只能一次次的求助汤川。</p>
<p>汤川：一个物理学教授。与石神、草薙同毕业于帝都大学，与石神互相欣赏、心心相惜，可以说是石神唯一的朋友。有着聪明的头脑，经常协助警方办理疑难杂案。由于对石神有着深入的了解，通过石神的行为细节推测出了石神参与靖子杀人案的动机和切入点，并随着深入的调查被石神的献身精神深深震惊。他完全理解石神，但对老友将要深陷囵圄、才华凋谢感到惋惜、痛心。</p>
<p>花冈美里：一个两度婚姻失败女人的孩子，对成年男子心存畏惧、不信任，但应该是信任石神的。或者正是美里最后的割腕自杀行为，让靖子突破了自我保护的最后防线，走进了警局。</p>
<p>最后：石神是不是真的是一个变态，我选择相信不是。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;富㭴慎二：一个看似成功的汽车销售，其实是利用职务之便挥霍公款，出手阔错。追求到花岗靖子，组成了一个看似美满的家庭。东窗事发后，被公司开除，露出了游手好闲的本性，变成一个吃软饭的无赖，离婚后还阴魂不散的缠着花岗靖子。&lt;/p&gt;
&lt;p&gt;花岗靖子：一个带着不算小魅力的单身女人，两度
    
    </summary>
    
    
      <category term="东野圭吾" scheme="https://liamlee.github.io/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/"/>
    
      <category term="读万卷书" scheme="https://liamlee.github.io/tags/%E8%AF%BB%E4%B8%87%E5%8D%B7%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://liamlee.github.io/2016/10/19/hello-world/"/>
    <id>https://liamlee.github.io/2016/10/19/hello-world/</id>
    <published>2016-10-19T05:22:14.000Z</published>
    <updated>2016-10-19T05:22:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
</feed>
